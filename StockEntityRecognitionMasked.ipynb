{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alpine-vietnam",
   "metadata": {},
   "source": [
    "# Stock Entity Recognition Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efficient-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import concurrent.futures\n",
    "import random\n",
    "\n",
    "from itertools import chain\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizerFast\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-qatar",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "THREADS = 48\n",
    "\n",
    "DEVICE = '/gpu:0'\n",
    "\n",
    "SUBMISSIONS_WITHOUT_SYMBOLS_LOC = 'data/ner/submissions_without_symbols.parquet'\n",
    "\n",
    "TOKENS_AND_LABELS_TRAIN_LOC = 'data/ner/tokens_and_labels_train.parquet'\n",
    "TOKENS_AND_LABELS_TEST_LOC = 'data/ner/tokens_and_labels_test.parquet'\n",
    "\n",
    "MODEL_LOC = 'data/ner/masked/best.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-revelation",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affected-junction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29383</th>\n",
       "      <td>pretty sure USO is the closest to 1:1 with raw...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109062</th>\n",
       "      <td>Everyone knows there’s 2 rules to follow: neve...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117238</th>\n",
       "      <td>Ford has been mismanaged for years . They cost...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36584</th>\n",
       "      <td>I own TERP . They will likely be bought out by...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125747</th>\n",
       "      <td>Just did a MMM 162.5c 3/6 . More masks please!</td>\n",
       "      <td>0 0 0 1 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147873</th>\n",
       "      <td>Watch a deal happens , we moon , then JP gets ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161762</th>\n",
       "      <td>Look up [TEMPEST](https://youtu.be/APBSaJ5AA_c...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72042</th>\n",
       "      <td>I had a bunch of SNDL I got cheap so I , too ,...</td>\n",
       "      <td>0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138661</th>\n",
       "      <td>Taking financial advice from a convicted felon...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67483</th>\n",
       "      <td>if you HAD TO choose , would you go with VOOor...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142674 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  \\\n",
       "29383   pretty sure USO is the closest to 1:1 with raw...   \n",
       "109062  Everyone knows there’s 2 rules to follow: neve...   \n",
       "117238  Ford has been mismanaged for years . They cost...   \n",
       "36584   I own TERP . They will likely be bought out by...   \n",
       "125747     Just did a MMM 162.5c 3/6 . More masks please!   \n",
       "...                                                   ...   \n",
       "147873  Watch a deal happens , we moon , then JP gets ...   \n",
       "161762  Look up [TEMPEST](https://youtu.be/APBSaJ5AA_c...   \n",
       "72042   I had a bunch of SNDL I got cheap so I , too ,...   \n",
       "138661  Taking financial advice from a convicted felon...   \n",
       "67483   if you HAD TO choose , would you go with VOOor...   \n",
       "\n",
       "                                                   labels  \n",
       "29383                               0 0 0 0 0 0 0 0 0 0 1  \n",
       "109062  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "117238  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 ...  \n",
       "36584   0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "125747                                0 0 0 1 0 0 0 0 0 0  \n",
       "...                                                   ...  \n",
       "147873  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "161762  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "72042   0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "138661                0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0  \n",
       "67483                     0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0  \n",
       "\n",
       "[142674 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_and_labels_train = pandas.read_parquet(TOKENS_AND_LABELS_TRAIN_LOC)\n",
    "tokens_and_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedded-savage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why do companies buy back shares?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Share buybacks should not change the value of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Directional iron condors using carefully place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>No You would have had to have earned income la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31250</th>\n",
       "      <td>Blowing versus sucking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31251</th>\n",
       "      <td>Not punny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31252</th>\n",
       "      <td>VWDRY is up 3.5% today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31254</th>\n",
       "      <td>Ticker: $FAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31255</th>\n",
       "      <td>I'm retarded.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>971817 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content\n",
       "3                                             Thank you.\n",
       "4                      why do companies buy back shares?\n",
       "5      Share buybacks should not change the value of ...\n",
       "11     Directional iron condors using carefully place...\n",
       "13     No You would have had to have earned income la...\n",
       "...                                                  ...\n",
       "31250                             Blowing versus sucking\n",
       "31251                                          Not punny\n",
       "31252                             VWDRY is up 3.5% today\n",
       "31254                                       Ticker: $FAG\n",
       "31255                                      I'm retarded.\n",
       "\n",
       "[971817 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load submissions without symbols to augment the masked observations and shuffle them\n",
    "submissions_without_symbols = pandas.read_parquet(SUBMISSIONS_WITHOUT_SYMBOLS_LOC)\n",
    "submissions_without_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "regulation-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9738"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_symbols():\n",
    "    exchanges = ['amex', 'nasdaq', 'nyse']\n",
    "\n",
    "    # create a dict of symbols to exchanges\n",
    "    symbols = set()\n",
    "    for exchange in exchanges:\n",
    "        exchange_symbols = pandas.read_csv(f'data/{exchange}_symbols.tsv', sep='\\t')\n",
    "        for index, row in exchange_symbols.iterrows():\n",
    "            symbols.add(row['Symbol'])\n",
    "        \n",
    "    return symbols\n",
    "\n",
    "# load a set of all symbols, were going to use this just to double check masking\n",
    "symbols = load_symbols()\n",
    "len(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outstanding-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_df(df, chunks):\n",
    "    chunk_size = len(df.index) / chunks\n",
    "    return [df[round(chunk_size * i):round(chunk_size * (i + 1))].copy(deep=True) for i in range(0, chunks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-bowling",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "We want to mask a token at a time and predict if the masked token is a stock symbol or not. We also want a even distribution of symbols and non-symbols so for every symbol in a sentence, create the same number of observations of masked non-symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moving-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_submission_with_symbols(row, observations=[]):\n",
    "    tokens = row['tokens'].split(' ')\n",
    "    labels = numpy.array(row['labels'].split(' ')).astype(int)\n",
    "    \n",
    "    # get all the token indexes that are symbols\n",
    "    symbols_idxs = numpy.nonzero(labels)[0]\n",
    "    \n",
    "    # since we only labeled less frequently used symbols, there would be more popular symbols that were not labeled so\n",
    "    # do one more pass to filter those out to avoid building incorrect examples with them\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token.upper() in symbols:\n",
    "            labels[i] = 1\n",
    "    \n",
    "    # get all the token indexes that are not symbols\n",
    "    all_non_symbol_idxs = numpy.nonzero(labels == 0)[0]\n",
    "    \n",
    "    # pick same number of random non symbol tokens, up to half\n",
    "    non_symbol_idxs = all_non_symbol_idxs[numpy.random.choice(\n",
    "        len(all_non_symbol_idxs), min(len(symbols_idxs), round(len(all_non_symbol_idxs) / 2)), replace=False\n",
    "    )]\n",
    "    \n",
    "    for idxs, label in [(symbols_idxs, 1), (non_symbol_idxs, 0)]:\n",
    "        for idx in idxs:\n",
    "            new_observation = tokens.copy()\n",
    "            new_observation[idx] = '[MASK]'\n",
    "            observations.append([' '.join(new_observation), label])\n",
    "            \n",
    "    return observations\n",
    "\n",
    "def mask_submissions_with_symbols(df):\n",
    "    observations = []\n",
    "    for _, row in df.iterrows():\n",
    "        mask_submission_with_symbols(row, observations)\n",
    "        \n",
    "    return observations\n",
    "\n",
    "def mask_submission_without_symbols(row, observations=[]):\n",
    "    if (pandas.isnull(row['content'])):\n",
    "        return observations\n",
    "    \n",
    "    tokens = row['content'].split(' ')\n",
    "\n",
    "    # mask a random token\n",
    "    tokens[random.randrange(len(tokens))] = '[MASK]'\n",
    "    \n",
    "    observations.append([' '.join(tokens), 0])\n",
    "            \n",
    "    return observations\n",
    "\n",
    "def mask_submissions_without_symbols(df):\n",
    "    observations = []\n",
    "    for _, row in df.iterrows():\n",
    "        mask_submission_without_symbols(row, observations)\n",
    "        \n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tired-trade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought [MASK] &amp; PACB so yea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I [MASK] CRSP &amp; PACB so yea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DD: my [MASK] pilot buddy is predicting that t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DD: my AA pilot buddy is predicting that they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>too late . In reality though the next service ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660193</th>\n",
       "      <td>[MASK]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660194</th>\n",
       "      <td>Poor Michael [MASK]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660195</th>\n",
       "      <td>[MASK]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660196</th>\n",
       "      <td>[MASK]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660197</th>\n",
       "      <td>like back [MASK] March?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  label\n",
       "0                           I bought [MASK] & PACB so yea      1\n",
       "1                             I [MASK] CRSP & PACB so yea      0\n",
       "2       DD: my [MASK] pilot buddy is predicting that t...      1\n",
       "3       DD: my AA pilot buddy is predicting that they ...      0\n",
       "4       too late . In reality though the next service ...      1\n",
       "...                                                   ...    ...\n",
       "660193                                             [MASK]      0\n",
       "660194                                Poor Michael [MASK]      0\n",
       "660195                                             [MASK]      0\n",
       "660196                                             [MASK]      0\n",
       "660197                            like back [MASK] March?      0\n",
       "\n",
       "[660198 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_observations = []\n",
    "\n",
    "# process training set which are submissions with symbols\n",
    "submissions_chunks = chunk_df(tokens_and_labels_train, THREADS)\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=THREADS) as executor:\n",
    "    futures = [executor.submit(mask_submissions_with_symbols, chunk) for chunk in submissions_chunks]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        training_observations.extend(future.result())\n",
    "\n",
    "# add some submissions without symbols so not biased to language of a specific type\n",
    "submissions_chunks = chunk_df(\n",
    "    submissions_without_symbols.sample(frac=1)[0:len(tokens_and_labels_train)], THREADS\n",
    ")\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=THREADS) as executor:\n",
    "    futures = [executor.submit(mask_submissions_without_symbols, chunk) for chunk in submissions_chunks]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        training_observations.extend(future.result())\n",
    "\n",
    "del submissions_chunks\n",
    "        \n",
    "training_observations = pandas.DataFrame(training_observations, columns=['tokens', 'label'])\n",
    "training_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aware-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_df(df, max_length=256):\n",
    "    # encode everything\n",
    "    inputs_encoded = tokenizer(\n",
    "        df['tokens'].tolist(), \n",
    "        return_tensors=\"tf\",\n",
    "        # make sure the same length across all encodings\n",
    "        max_length=max_length, \n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "        \n",
    "    labels_encoded = numpy.array(df['label']).reshape((df.shape[0], 1))\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(({\n",
    "        'input_ids': inputs_encoded['input_ids'],\n",
    "        'token_type_ids': inputs_encoded['token_type_ids'],\n",
    "        'attention_mask': inputs_encoded['attention_mask']\n",
    "    }, labels_encoded)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "olive-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and encode\n",
    "encoded_dataset = encode_df(training_observations.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_LOC,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(encoded_dataset, epochs=5, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-answer",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wired-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa27d7d8b80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.load_weights(MODEL_LOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "worst-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, max_length=256):\n",
    "    encoding = tokenizer(\n",
    "        sentence, \n",
    "        return_tensors=\"tf\",\n",
    "        # make sure the same length across all encodings\n",
    "        max_length=max_length, \n",
    "        padding='max_length',\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    prediction = tf.argmax(model(encoding).logits[0])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "early-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 1.3705293, -1.370667 ], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "understood-terrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>MSFT , V , BRK.B , AAPL , JNJ</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38806</th>\n",
       "      <td>Yes . Look at oil company Whiting Petroleum . ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115771</th>\n",
       "      <td>INO and ten cent plays?</td>\n",
       "      <td>1 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30274</th>\n",
       "      <td>SE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52170</th>\n",
       "      <td>one is the MSI index.</td>\n",
       "      <td>0 0 0 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45078</th>\n",
       "      <td>EOG is at a pretty good price right now IMO . ...</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166128</th>\n",
       "      <td>HPQ To the mooooooooon</td>\n",
       "      <td>1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52986</th>\n",
       "      <td>Ah , didn't realize Yahoo only updated the NAV...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162531</th>\n",
       "      <td>Sears BK , Mattress Firm BK What is the best w...</td>\n",
       "      <td>0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7017</th>\n",
       "      <td>I think Robo accounts are great for people tha...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35669 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tokens  \\\n",
       "56037                       MSFT , V , BRK.B , AAPL , JNJ   \n",
       "38806   Yes . Look at oil company Whiting Petroleum . ...   \n",
       "115771                            INO and ten cent plays?   \n",
       "30274                                                  SE   \n",
       "52170                               one is the MSI index.   \n",
       "...                                                   ...   \n",
       "45078   EOG is at a pretty good price right now IMO . ...   \n",
       "166128                             HPQ To the mooooooooon   \n",
       "52986   Ah , didn't realize Yahoo only updated the NAV...   \n",
       "162531  Sears BK , Mattress Firm BK What is the best w...   \n",
       "7017    I think Robo accounts are great for people tha...   \n",
       "\n",
       "                                                   labels  \n",
       "56037                                   0 0 0 0 0 0 0 0 1  \n",
       "38806   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "115771                                          1 0 0 0 0  \n",
       "30274                                                   1  \n",
       "52170                                           0 0 0 1 0  \n",
       "...                                                   ...  \n",
       "45078   1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "166128                                            1 0 0 0  \n",
       "52986                             0 0 0 0 0 0 0 0 1 0 0 0  \n",
       "162531  0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 ...  \n",
       "7017    0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "\n",
       "[35669 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_and_labels_test = pandas.read_parquet(TOKENS_AND_LABELS_TEST_LOC)\n",
    "tokens_and_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "collective-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(submissions_without_symbols.iloc[]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit",
   "language": "python",
   "name": "reddit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
